{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0N1-CQlEPim",
        "outputId": "a52f92b2-98c4-4363-b6f4-f0c312fee701"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import io\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# Force PyTorch to use CPU\n",
        "#device = torch.device(\"cpu\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(\"Using device:\", device)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# def load_financial_phrasebank():\n",
        "#     \"\"\"Load and preprocess the Financial PhraseBank df.\"\"\"\n",
        "#     print(\"Loading Financial PhraseBank df...\")\n",
        "#     data = []\n",
        "#     with open(\"/Sentences_50Agree.txt\", \"r\",\n",
        "#               encoding=\"ISO-8859-1\") as file:\n",
        "#         for line in file:\n",
        "#             text, sentiment = line.rsplit(\"@\", 1)\n",
        "#             sentiment = sentiment.strip()\n",
        "#             label = {\"neutral\": 0, \"positive\": 1, \"negative\": 2}.get(sentiment, 0)\n",
        "#             data.append({\"text\": text.strip(), \"sentiment\": label})\n",
        "\n",
        "#     df = pd.DataFrame(data)\n",
        "#     return df\n",
        "\n",
        "def load_financial_phrasebank():\n",
        "    data = []\n",
        "    with open(\"/Sentences_50Agree.txt\", \"r\",\n",
        "              encoding=\"ISO-8859-1\") as file:\n",
        "        for line in file:\n",
        "            text, sentiment = line.rsplit(\"@\", 1)\n",
        "            sentiment = sentiment.strip()\n",
        "            # Check what order you used here during training\n",
        "            label = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}.get(sentiment, 0)\n",
        "            data.append({\"text\": text.strip(), \"sentiment\": label})\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    return df\n",
        "\n",
        "\n",
        "df = load_financial_phrasebank()\n",
        "df.head()\n",
        "print(df['sentiment'].value_counts())\n",
        "# print(df.head())\n",
        "#\n",
        "# print(df.loc[df.sentiment == 0].sample(5)[['text', 'sentiment']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OW0rSihFYvp",
        "outputId": "0e5d4bd2-183d-4053-d3e4-02f151bde154"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentiment\n",
            "1    2879\n",
            "2    1363\n",
            "0     604\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "gtZ8zIUFJGAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contents = df.text.values\n",
        "labels = df.sentiment.values\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# print(tokenizer.tokenize(contents[0]))\n",
        "# print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(contents[0])))\n",
        "# input_ids = torch.tensor(tokenizer.encode('this is a cat', add_special_tokens=True, truncation=True, max_length = 10, padding = True)).unsqueeze(0)\n",
        "# print(input_ids)\n",
        "\n",
        "max_len = 0\n",
        "\n",
        "for sentence in contents:\n",
        "    input_ids = torch.tensor(tokenizer.encode(sentence, add_special_tokens=True))\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "max_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XT2oGiDHhXo",
        "outputId": "a13f438f-1f72-4fb3-8d7b-f9d782de36a0"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "150"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in contents:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,\n",
        "                        add_special_tokens = True, # add [CLS] and [SEP]\n",
        "                        truncation=True,\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        padding='max_length',\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn masks.\n",
        "                        return_tensors = 'pt',     # return pytorch tensors.\n",
        "                   )\n",
        "\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "#sentence 0 as list of ids\n",
        "print('Original: ', contents[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEatGeUcKxSp",
        "outputId": "459f19a3-6550-4627-ceb5-ccb399bf6528"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .\n",
            "Token IDs: tensor([  101,  2429,  2000, 12604,  1010,  1996,  2194,  2038,  2053,  3488,\n",
            "         2000,  2693,  2035,  2537,  2000,  3607,  1010,  2348,  2008,  2003,\n",
            "         2073,  1996,  2194,  2003,  3652,  1012,   102,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# train_size = int(0.85 * len(dataset))\n",
        "# val_size = len(dataset) - train_size\n",
        "\n",
        "# # divide dataset by randomly selecting samples.\n",
        "# train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# print('{:>5,} training samples'.format(train_size))\n",
        "# print('{:>5,} validation samples'.format(val_size))\n",
        "\n",
        "# # Add these after creating your dataset\n",
        "# print(\"Unique labels in dataset:\", torch.unique(labels))\n",
        "# print(\"Label distribution:\", torch.bincount(labels))\n",
        "\n",
        "\n",
        "# Define split ratios\n",
        "train_ratio = 0.7\n",
        "val_ratio = 0.15\n",
        "test_ratio = 0.15\n",
        "\n",
        "# Compute dataset sizes\n",
        "train_size = int(train_ratio * len(dataset))\n",
        "val_size = int(val_ratio * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size  # Ensure total size is correct\n",
        "\n",
        "# Split dataset into train, validation, and test sets\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "# Print dataset sizes\n",
        "print(f\"Train samples: {train_size}\")\n",
        "print(f\"Validation samples: {val_size}\")\n",
        "print(f\"Test samples: {test_size}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it\n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch\n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order.\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # training samples.\n",
        "            sampler = RandomSampler(train_dataset), # get batches randomly\n",
        "            batch_size = batch_size # trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset,\n",
        "    sampler=SequentialSampler(test_dataset),\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJ0k8cTjLAUH",
        "outputId": "44de982f-0317-4953-f228-e83e1b2f703a"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train samples: 3392\n",
            "Validation samples: 726\n",
            "Test samples: 728\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single\n",
        "# linear classification layer on top.\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 3, # The number of output labels--2 for binary classification.\n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        "    return_dict = False\n",
        ")\n",
        "model.train()\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()\n",
        "\n",
        "\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "\n",
        "\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guTXLSWdLJ91",
        "outputId": "5d67ca56-529b-4b26-a13a-6e65278d0932"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (3, 768)\n",
            "classifier.bias                                                 (3,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 2\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs].\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "id": "iCWuWT8BLQFa"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "metadata": {
        "id": "bIK4stRGLYbN"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "\n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader.\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass.\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        outputs = model(b_input_ids,\n",
        "                             token_type_ids=None,\n",
        "                             attention_mask=b_input_mask,\n",
        "                             labels=b_labels)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "\n",
        "        print(\"\\/\\/\\/\\/\\/\\/\\/\")\n",
        "        print(\"Loss:\", loss)\n",
        "        print(\"Logits shape:\", logits.shape)\n",
        "        print(\"Labels shape:\", b_labels.shape)\n",
        "        print(\"Unique labels:\", torch.unique(b_labels))\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value\n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        # Unpack this training batch from our dataloader.\n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using\n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids\n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which\n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here:\n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            (loss, logits) = model(b_input_ids,\n",
        "                                   token_type_ids=None,\n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "\n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "\n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time() - total_t0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wqMwPLMLfB-",
        "outputId": "b2019ff3-ece6-48d4-9127-9ea55c1da98c"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(1.1559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(1.0919, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(1.0407, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(1.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(1.0151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.9530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(1.0178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.9396, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.9267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.9852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(1.0164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.8323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(1.1009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.8823, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.9251, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.8389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(1.0590, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.8615, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.8863, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.9499, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.7308, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.8524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(1.0049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.8509, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.8960, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.6885, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.8599, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.9035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.7480, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.7412, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.6964, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.7433, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.9805, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.6382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.7697, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.6250, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.6752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.5863, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.6055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.8524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "  Batch    40  of    106.    Elapsed: 0:00:12.\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.8065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.6414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.6996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.6631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.7748, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.6201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.6385, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.8194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.7139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.6750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.6055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.6231, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.5649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3652, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.4804, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.7154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.4210, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.5369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.6557, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.4601, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3370, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.5944, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.4726, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.6235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.4840, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.4834, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.4522, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.5207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3868, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.4845, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.7776, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.4802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.5076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.4374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.4465, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.4223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.6296, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.5037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.4693, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.6399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "  Batch    80  of    106.    Elapsed: 0:00:24.\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.4573, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.4901, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3695, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.5487, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.5066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.5431, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.4897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3237, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.6995, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.5863, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.6134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.4174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3348, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.6999, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.5506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.5259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2989, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.5983, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3614, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\n",
            "  Average training loss: 0.65\n",
            "  Training epcoh took: 0:00:32\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "  Validation Loss: 0.39\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3859, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3681, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2348, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3977, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3432, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2880, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.5071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2250, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3587, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.4962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3688, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2873, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3901, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2776, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.5133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2714, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1933, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2739, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.4437, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2937, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.4082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3541, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2941, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3379, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3844, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.5039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3912, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "  Batch    40  of    106.    Elapsed: 0:00:12.\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3581, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3550, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.5795, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3303, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.4078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3375, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2859, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3918, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.4554, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2993, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3557, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.4922, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1693, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1463, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3558, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3720, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1674, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.4869, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2876, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2425, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2642, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.4710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1870, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2250, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2300, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "  Batch    80  of    106.    Elapsed: 0:00:25.\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.5566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2924, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3669, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.4674, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2444, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3756, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3383, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3520, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2888, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.5554, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2705, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.5571, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3635, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.4159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1691, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3933, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2853, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2554, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3260, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.5155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\n",
            "  Average training loss: 0.32\n",
            "  Training epcoh took: 0:00:33\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "  Validation Loss: 0.33\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1602, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1792, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1347, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1733, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1595, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0812, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2540, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0885, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3272, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0951, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1410, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0732, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0994, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1574, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1324, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1835, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1822, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0582, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1938, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1789, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0747, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1966, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "  Batch    40  of    106.    Elapsed: 0:00:13.\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2674, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0986, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1720, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2445, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2696, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3376, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2343, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2969, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0786, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2997, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1497, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1227, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1778, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1647, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0704, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1246, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1685, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "  Batch    80  of    106.    Elapsed: 0:00:26.\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0780, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1809, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0931, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2930, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0410, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2293, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.4592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3433, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1299, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1462, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1822, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\n",
            "  Average training loss: 0.18\n",
            "  Training epcoh took: 0:00:34\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "  Validation Loss: 0.40\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0728, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1842, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0721, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1977, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2569, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0437, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0519, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1849, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0489, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0596, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1983, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0881, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1902, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0541, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0642, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0696, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0411, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0479, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "  Batch    40  of    106.    Elapsed: 0:00:13.\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0412, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0290, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1580, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1951, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3422, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0755, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0697, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0293, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2708, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0642, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0779, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0385, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0509, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0894, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0551, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1504, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0479, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1343, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1582, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2811, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0873, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0862, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2328, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0556, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2795, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0672, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "  Batch    80  of    106.    Elapsed: 0:00:26.\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0349, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1558, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0869, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0867, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0672, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0703, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.3453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0666, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0902, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0977, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0712, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1505, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0999, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1552, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.0736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2327, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.2175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\\/\\/\\/\\/\\/\\/\\/\n",
            "Loss: tensor(0.1308, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Logits shape: torch.Size([32, 3])\n",
            "Labels shape: torch.Size([32])\n",
            "Unique labels: tensor([0, 1, 2], device='cuda:0')\n",
            "\n",
            "  Average training loss: 0.11\n",
            "  Training epcoh took: 0:00:35\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "  Validation Loss: 0.42\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:02:24 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nRunning Test Evaluation...\")\n",
        "\n",
        "t0 = time.time()\n",
        "model.eval()\n",
        "\n",
        "total_test_accuracy = 0\n",
        "total_test_loss = 0\n",
        "\n",
        "for batch in test_dataloader:\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        (loss, logits) = model(b_input_ids,\n",
        "                               token_type_ids=None,\n",
        "                               attention_mask=b_input_mask,\n",
        "                               labels=b_labels)\n",
        "\n",
        "    total_test_loss += loss.item()\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    total_test_accuracy += flat_accuracy(logits, label_ids)\n",
        "\n",
        "avg_test_accuracy = total_test_accuracy / len(test_dataloader)\n",
        "avg_test_loss = total_test_loss / len(test_dataloader)\n",
        "\n",
        "print(\"  Test Accuracy: {0:.2f}\".format(avg_test_accuracy))\n",
        "print(\"  Test Loss: {0:.2f}\".format(avg_test_loss))\n",
        "print(\"  Test Evaluation took: {:}\".format(format_time(time.time() - t0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "De5_5MmtQG5C",
        "outputId": "294fdad3-3479-402a-cc2e-b52d2ed016ee"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Test Evaluation...\n",
            "  Test Accuracy: 0.84\n",
            "  Test Loss: 0.48\n",
            "  Test Evaluation took: 0:00:02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = './model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAMCQchKRD1s",
        "outputId": "4aa51330-a16d-4a73-e3af-76b0710a73ec"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to ./model_save/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./model_save/tokenizer_config.json',\n",
              " './model_save/special_tokens_map.json',\n",
              " './model_save/vocab.txt',\n",
              " './model_save/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.path.exists(\"./model_save/\"))\n",
        "print(os.listdir(\"./\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTTDyUkaSEfg",
        "outputId": "ffd2435e-9601-4c5a-859f-c675a9e636c3"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "['.config', 'drive', 'model_save', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcWw1T9jSWll",
        "outputId": "b6c070f9-fd26-47c1-f0bc-f3f23fd3bbdc"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy the model files to a directory in your Google Drive.\n",
        "#!cp -r ./model_save/ \"./drive/Shared drives/ChrisMcCormick.AI/Blog Posts/BERT Fine-Tuning/\"\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "# Define the correct path for the models_saved folder\n",
        "save_path = \"/content/drive/MyDrive/models_saved/\"\n",
        "\n",
        "# Create the folder if it doesn't exist\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "model.save_pretrained(save_path)"
      ],
      "metadata": {
        "id": "dM7cFopmSrIz"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.utils import class_weight\n",
        "# import torch\n",
        "# import numpy as np\n",
        "# from transformers import BertForSequenceClassification, BertTokenizer\n",
        "\n",
        "# # Load the model and tokenizer\n",
        "# model_path = \"/content/drive/MyDrive/models_saved\"\n",
        "# tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "# model = BertForSequenceClassification.from_pretrained(model_path)\n",
        "# model.eval()\n",
        "\n",
        "# # Ensure labels are loaded correctly\n",
        "# if isinstance(labels, np.ndarray):  # If labels are a NumPy array\n",
        "#     labels_numpy = labels.flatten()  # Ensure it's a 1D array\n",
        "# else:\n",
        "#     raise ValueError(f\"Error: labels is of type {type(labels)} and is not a NumPy array.\")\n",
        "\n",
        "# # Check the unique values in the labels array\n",
        "# print(\"Unique labels before cleaning:\", np.unique(labels_numpy))\n",
        "\n",
        "# # Check if any ellipsis or invalid values are present\n",
        "# if np.any(labels_numpy == Ellipsis):\n",
        "#     print(\"Warning: Ellipsis ('...') detected in labels array.\")\n",
        "#     # Clean up: remove ellipsis values if present\n",
        "#     labels_numpy = labels_numpy[labels_numpy != Ellipsis]\n",
        "\n",
        "# # Ensure labels are clean and of integer type (if necessary)\n",
        "# labels_numpy = labels_numpy.astype(int)\n",
        "\n",
        "# # Check the first few labels to confirm the data\n",
        "# print(\"Sample labels:\", labels_numpy[:10])\n",
        "\n",
        "# # Compute class weights using the labels\n",
        "# try:\n",
        "#     class_weights = class_weight.compute_class_weight(\n",
        "#         class_weight='balanced',\n",
        "#         classes=np.unique(labels_numpy),  # Classes should be unique labels\n",
        "#         y=labels_numpy  # Your labels\n",
        "#     )\n",
        "#     print(\"Class weights computed:\", class_weights)\n",
        "# except ValueError as e:\n",
        "#     print(\"Error computing class weights:\", e)\n",
        "#     print(\"Unique values in labels:\", np.unique(labels_numpy))\n",
        "\n",
        "# # Convert class weights to a tensor and move to device (GPU if available)\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# class_weights_tensor = torch.from_numpy(class_weights).float().to(device)\n",
        "\n",
        "# # Print the results\n",
        "# print(\"Class weights tensor:\", class_weights_tensor)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "T7qnWDZBTn0i",
        "outputId": "17a4d139-08ca-4179-b561-14543c3ce930"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'<' not supported between instances of 'ellipsis' and 'int'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-8efd55f377b0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Check the unique values in the labels array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unique labels before cleaning:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_numpy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Check if any ellipsis or invalid values are present\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         ret = _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[0m\u001b[1;32m    275\u001b[0m                         equal_nan=equal_nan)\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'ellipsis' and 'int'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "import torch\n",
        "\n",
        "# Path to the saved model\n",
        "model_path = \"/content/drive/MyDrive/models_saved\"  # Adjust this path if needed\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Load the model\n",
        "model = BertForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Define a function to preprocess the input text\n",
        "def preprocess_text(text, tokenizer, max_length=512):\n",
        "    # Tokenize the input text\n",
        "    encoding = tokenizer.encode_plus(\n",
        "        text,                      # Input text\n",
        "        add_special_tokens=True,    # Add special tokens like [CLS] and [SEP]\n",
        "        max_length=max_length,     # Maximum length of the tokenized sequence\n",
        "        padding='max_length',       # Pad to max_length\n",
        "        truncation=True,            # Truncate if it's longer than max_length\n",
        "        return_tensors='pt',        # Return as PyTorch tensor\n",
        "    )\n",
        "\n",
        "    return encoding\n",
        "\n",
        "# Example input text (news article)\n",
        "# text = \"The stock market saw a significant drop today after disappointing earnings reports from major tech companies.\"\n",
        "text = \"The stock market saw a significant rise today after announced new product launch\"\n",
        "\n",
        "\n",
        "# Preprocess the input text\n",
        "inputs = preprocess_text(text, tokenizer)\n",
        "\n",
        "# Make the prediction\n",
        "with torch.no_grad():  # Disable gradient calculations for inference\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "# Get the logits (the raw prediction scores)\n",
        "logits = outputs[0]\n",
        "\n",
        "# Convert logits to probabilities using softmax\n",
        "probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
        "\n",
        "# Get the predicted sentiment (class)\n",
        "predicted_class = torch.argmax(probabilities, dim=-1).item()\n",
        "\n",
        "# Print the result\n",
        "print(f\"Predicted class: {predicted_class}\")\n",
        "print(f\"Probabilities: {probabilities}\")\n",
        "\n",
        "sentiment_classes = [\"negative\", \"neutral\", \"positive\"]\n",
        "\n",
        "print(f\"Predicted sentiment: {sentiment_classes[predicted_class]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLXuOaibVHdW",
        "outputId": "3a8abdd6-3738-4ab5-d97b-924475a3654e"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: 2\n",
            "Probabilities: tensor([[0.0032, 0.0064, 0.9904]])\n",
            "Predicted sentiment: positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eT9QTvyzqmej"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}